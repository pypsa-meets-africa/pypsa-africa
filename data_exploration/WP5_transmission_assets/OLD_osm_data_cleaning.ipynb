{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "OLD NOTEBOOK: SEE osm_pbf_power_data_extractor.py which does everything."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#check folder\r\n",
    "\r\n",
    "import os, sys, time\r\n",
    "(os.path.abspath(''))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Davide\\\\Git\\\\pypsa-africa\\\\data_exploration\\\\WP5_transmission_assets'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import os, sys, time\r\n",
    "#IMPORTANT: RUN SCRIPT FROM THIS SCRIPTS DIRECTORY i.e data_exploration/ TODO: make more robust\r\n",
    "## os.chdir(os.path.dirname(os.path.abspath(__file__)))\r\n",
    "sys.path.append('../../scripts')\r\n",
    "from iso_country_codes import AFRICA_CC\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import geopandas as gpd\r\n",
    "from shapely.geometry import Point, LineString\r\n",
    "import geoplot\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from iso_country_codes import AFRICA_CC\r\n",
    "from osm_pbf_power_data_extractor import convert_pd_to_gdf_lines, convert_pd_to_gdf\r\n",
    "\r\n",
    "import logging\r\n",
    "logger = logging.getLogger(__name__)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SUBSTATIONS (Just simple cleaning to test snapping)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check old buses"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Load pypsa-eur data\r\n",
    "df_all_buses = (pd.read_csv(os.getcwd()+\"/entsoegridkit/buses.csv\", quotechar=\"'\",\r\n",
    "                         true_values='t', false_values='f',\r\n",
    "                         dtype=dict(bus_id=\"str\"))\r\n",
    "            .set_index(\"bus_id\")\r\n",
    "            .drop(['station_id'], axis=1)\r\n",
    "            .rename(columns=dict(voltage='v_nom')))\r\n",
    "\r\n",
    "#print(df_all_lines.geometry.unique())\r\n",
    "#display(df_all_buses)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import data and create final dataframe layout"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "#----------- SUBSTATIONS -----------\r\n",
    "# Load uncleaned data\r\n",
    "df_all_substations = gpd.read_file(os.getcwd()+\"/data/raw/africa_all_raw_substations.geojson\")\r\n",
    "\r\n",
    "# Modification - create final dataframe layout\r\n",
    "df_all_substations = df_all_substations.rename(\r\n",
    "    columns = {\r\n",
    "        \"id\": \"bus_id\",\r\n",
    "        \"tags.voltage\": \"voltage\",\r\n",
    "        # \"dc\", will be added below\r\n",
    "        \"tags.power\": \"symbol\",\r\n",
    "        # \"under_construction\", will be added below     \r\n",
    "        \"tags.substation\": \"tag_substation\",\r\n",
    "        \"Country\": \"country\",  # new/different to PyPSA-Eur\r\n",
    "        \"Area\": \"tag_area\",\r\n",
    "        \"lonlat\": \"geometry\",\r\n",
    "    }\r\n",
    ")\r\n",
    "\r\n",
    "# Add NaN as default\r\n",
    "df_all_substations[\"station_id\"] = np.nan\r\n",
    "df_all_substations[\"dc\"] = np.nan\r\n",
    "df_all_substations[\"under_construction\"] = np.nan\r\n",
    "df_all_substations[\"lon\"] = df_all_substations[\"geometry\"].x\r\n",
    "df_all_substations[\"lat\"] = df_all_substations[\"geometry\"].y\r\n",
    "\r\n",
    "#Rearrange columns\r\n",
    "clist = [\"bus_id\",\"station_id\",\"voltage\",\"dc\",\"symbol\",\"under_construction\",\"tag_substation\",\r\n",
    "         \"tag_area\",\"lon\", \"lat\", \"geometry\",\"country\"]\r\n",
    "df_all_substations = df_all_substations[clist]\r\n",
    "\r\n",
    "# make float to integer\r\n",
    "df_all_substations[\"bus_id\"] = df_all_substations[\"bus_id\"].astype(int)\r\n",
    "\r\n",
    "#display(df_all_substations)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define under_construction, dc, filter \"transmission\""
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "df_all_substations[\"under_construction\"] = True\r\n",
    "df_all_substations[\"dc\"] = False\r\n",
    "df_all_substations = df_all_substations[df_all_substations[\"tag_substation\"] == \"transmission\"] # keep only rows with indexed \"transmission\"\r\n",
    "#display(df_all_substations)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# df_all_substations.tags_area.count()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# df_all_substations[df_all_substations[\"tags_substation\"] == \"transmission\"].tags_area.describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# df_all_substations[df_all_substations[\"tags_substation\"] == \"distribution\"].tags_area.describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# df_all_substations[df_all_substations[\"tags_substation\"] == \"industrial\"].tags_area.describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# df_all_substations[df_all_substations[\"tags_substation\"].isna()].tags_area.describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# df_all_substations[\"tags_substation\"].unique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Clean voltage"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# Drop any row with Voltage = N/A\r\n",
    "df = df_all_substations.dropna(subset=['voltage']) \r\n",
    "\r\n",
    "#Split semicolon separated cells i.e. [66000;220000] and create new identical rows\r\n",
    "lst_col = 'voltage'\r\n",
    "x = df.assign(**{lst_col:df[lst_col].str.split(';')})\r\n",
    "x = pd.DataFrame({\r\n",
    "    col:np.repeat(x[col].values, x[lst_col].str.len())\r\n",
    "    for col in x.columns.difference([lst_col])\r\n",
    "    }).assign(**{lst_col:np.concatenate(x[lst_col].values)})[x.columns.tolist()]\r\n",
    "df_all_substations = x\r\n",
    "\r\n",
    "#display(df_all_substations)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# Create unique bus id's\r\n",
    "# The steps below create unique bus id's without loosing the original OSM bus_id \r\n",
    "\r\n",
    "# Context\r\n",
    "# The previous duplication of rows (to split the voltage) lead to a couple of same bus_id\r\n",
    "\r\n",
    "# Method\r\n",
    "# Unique bus_id are created by simply adding -1,-2,-3 to the original bus_id\r\n",
    "# Every unique id gets a -1 \r\n",
    "# If a bus_id exist i.e. three times it it will the counted by cumcount -1,-2,-3 making the id unique\r\n",
    "\r\n",
    "if df_all_substations[\"bus_id\"].count() != df_all_substations[\"bus_id\"].nunique(): # operate only if line_id is not already unique (nunique counts unique values)\r\n",
    "    df_all_substations[\"cumcount\"] = df_all_substations.groupby([\"bus_id\"]).cumcount() # create cumcount column. Cumcount counts 0,1,2,3 the number of duplicates\r\n",
    "    df_all_substations[\"cumcount\"] = df_all_substations[\"cumcount\"] + 1 # avoid 0 value for better understanding\r\n",
    "    df_all_substations[\"bus_id\"] = df_all_substations[\"bus_id\"].astype(str) + \"-\" + df_all_substations[\"cumcount\"].values.astype(str) # add cumcount to line_id to make line_id unique\r\n",
    "    df_all_substations.drop(columns = \"cumcount\", inplace=True) # remove cumcount column\r\n",
    "\r\n",
    "#display(df_all_substations)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# Remove all non-numeric values\r\n",
    "\r\n",
    "df_all_substations['voltage'] = df_all_substations['voltage'].apply(lambda x: pd.to_numeric(x, errors='coerce')).astype(float) # if cell can't converted to float -> nan\r\n",
    "df_all_substations = df_all_substations.dropna(subset=['voltage']) # Drop any row with Voltage = N/A\r\n",
    "df_all_substations.loc[:,\"voltage\"]  = df_all_substations['voltage'].astype(int)\r\n",
    "#df_all_lines['voltage'].unique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "# Keep rows with x > 110 kV as it is considered as transmission level\r\n",
    "\r\n",
    "df_all_substations = df_all_substations[df_all_substations.voltage > 110000]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "# display(df_all_substations)\r\n",
    "# display(df_all_substations['voltage'].unique())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "## Generate Files (CSV+GeoJSON) \r\n",
    "\r\n",
    "#### CSV\r\n",
    "outputfile_partial = os.path.join(os.getcwd(), \"data\", \"clean\", \"africa_all\" + \"_buses\" + \"_clean\") # Output file directory\r\n",
    "\r\n",
    "if not os.path.exists(outputfile_partial):\r\n",
    "    os.makedirs(os.path.dirname(outputfile_partial), exist_ok=True) #  create clean directoryif not already exist\r\n",
    "    \r\n",
    "df_all_substations.to_csv(outputfile_partial + \".csv\")  # Generate CSV\r\n",
    "\r\n",
    "\r\n",
    "#### GEOJSON\r\n",
    "\r\n",
    "df_all_substations = gpd.GeoDataFrame(df_all_substations, geometry=\"geometry\",crs=\"EPSG:4326\")\r\n",
    "df_all_substations.to_file(outputfile_partial + \".geojson\", driver=\"GeoJSON\")    \r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:fiona._env:c:\\Users\\Davide\\Git\\pypsa-africa\\data_exploration\\WP5_transmission_assets\\data\\clean\\africa_all_buses_clean.geojson: No such file or directory\n",
      "WARNING:fiona._env:driver GeoJSON does not support creation option ENCODING\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LINES "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check old unique values"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "# Load pypsa-eur data\r\n",
    "df_all_lines = (pd.read_csv(os.getcwd()+\"/entsoegridkit/lines.csv\", quotechar=\"'\", true_values='t', false_values='f',\r\n",
    "                         dtype=dict(line_id='str', bus0='str', bus1='str',\r\n",
    "                                    underground=\"bool\", under_construction=\"bool\")).set_index('line_id').rename(columns=dict(voltage='v_nom', circuits='num_parallel')))\r\n",
    "\r\n",
    "#print(df_all_lines.geometry.unique())\r\n",
    "#display(df_all_lines)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import data and create final dataframe layout"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load cables"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "# Load raw cable data\r\n",
    "df_cables = gpd.read_file(os.getcwd()+\"/data/raw/africa_all_raw_cables.geojson\") \r\n",
    "\r\n",
    "# Modification - create final dataframe layout\r\n",
    "df_cables = df_cables.rename(\r\n",
    "    columns = {\r\n",
    "        \"id\": \"line_id\",\r\n",
    "        \"tags.voltage\": \"voltage\",\r\n",
    "        \"tags.circuits\": \"circuits\",\r\n",
    "        \"tags.cables\": \"cables\",\r\n",
    "        \"tags.frequency\": \"tag_frequency\",\r\n",
    "        \"tags.power\": \"tag_type\",\r\n",
    "        \"tags.location\": \"tag_location\",\r\n",
    "        \"lonlat\": \"geometry\",\r\n",
    "        \"Country\": \"country\",  # new/different to PyPSA-Eur\r\n",
    "        \"Length\": \"length\",\r\n",
    "    }\r\n",
    ")\r\n",
    "\r\n",
    "# Add NaN as default\r\n",
    "df_cables[\"bus0\"] = np.nan\r\n",
    "df_cables[\"bus1\"] = np.nan\r\n",
    "#df_all_cables[\"length\"] = np.nan # Now in dataset\r\n",
    "df_cables[\"underground\"] = np.nan\r\n",
    "df_cables[\"under_construction\"] = np.nan\r\n",
    "\r\n",
    "#Rearrange columns\r\n",
    "clist = [\"line_id\",\"bus0\",\"bus1\",\"voltage\",\"circuits\",\"length\",\"underground\",\r\n",
    "         \"under_construction\",\"tag_type\",\"tag_frequency\", \"tag_location\",\"geometry\", \"country\"]\r\n",
    "df_cables = df_cables[clist]\r\n",
    "\r\n",
    "# make float to integer\r\n",
    "df_cables[\"line_id\"] = df_cables[\"line_id\"].astype(int)\r\n",
    "\r\n",
    "\r\n",
    "#display(df_cables)\r\n",
    "#df_all_cables[df_all_cables['tag_location']== \"overground\"]\r\n",
    "#df_all_cables[\"tags.location\"].unique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load lines"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "# Load raw line data\r\n",
    "df_lines = gpd.read_file(os.getcwd()+\"/data/raw/africa_all_raw_lines.geojson\") \r\n",
    "\r\n",
    "# Modification - create final dataframe layout\r\n",
    "df_lines = df_lines.rename(\r\n",
    "    columns = {\r\n",
    "        \"id\": \"line_id\",\r\n",
    "        \"tags.voltage\": \"voltage\",\r\n",
    "        \"tags.circuits\": \"circuits\",\r\n",
    "        \"tags.cables\": \"cables\",\r\n",
    "        \"tags.frequency\": \"tag_frequency\",\r\n",
    "        \"tags.power\": \"tag_type\",\r\n",
    "        \"lonlat\": \"geometry\",\r\n",
    "        \"Country\": \"country\",  # new/different to PyPSA-Eur\r\n",
    "        \"Length\": \"length\",\r\n",
    "    }\r\n",
    ")\r\n",
    "\r\n",
    "# Add NaN as default\r\n",
    "df_lines[\"bus0\"] = np.nan\r\n",
    "df_lines[\"bus1\"] = np.nan\r\n",
    "#df_all_lines[\"length\"] = np.nan # commented because, we have now length data\r\n",
    "df_lines[\"underground\"] = np.nan\r\n",
    "df_lines[\"under_construction\"] = np.nan\r\n",
    "\r\n",
    "#Rearrange columns\r\n",
    "clist = [\"line_id\",\"bus0\",\"bus1\",\"voltage\",\"circuits\",\"length\",\"underground\",\r\n",
    "         \"under_construction\",\"tag_type\",\"tag_frequency\", \"cables\",\"geometry\", \"country\"]\r\n",
    "df_lines = df_lines[clist]\r\n",
    "\r\n",
    "#display(df_all_lines)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combine cable and line to one  \"df_all_lines\" dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "df_all_lines = pd.concat([df_lines,df_cables])\r\n",
    "# df_all_lines"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define underground, under_construction information, frequency, circuits"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "# under construction\r\n",
    "df_all_lines[\"under_construction\"] = False # default. Not more information atm available\r\n",
    "\r\n",
    "# underground\r\n",
    "df_all_lines[\"underground\"] = (df_all_lines[\"tag_type\"] == \"cable\") # Simplified. If tag_type cable then underground is True. \r\n",
    "# More information extractable for \"underground\" by looking at \"tag_location\".\r\n",
    "if 'tag_location' in df_all_lines: # drop column if exist\r\n",
    "    df_all_lines.drop(columns = \"tag_location\", inplace=True)\r\n",
    "\r\n",
    "# frequency\r\n",
    "df_all_lines[\"tag_frequency\"] = 50\r\n",
    "#df_all_lines[\"tag_frequency\"].unique()\r\n",
    "\r\n",
    "# circuits\r\n",
    "if df_all_lines[\"cables\"].dtype != int: # if not int make int\r\n",
    "    df_all_lines.loc[(df_all_lines[\"cables\"] < \"3\") | df_all_lines[\"cables\"].isna(), \"cables\"] = \"0\" #HERE. \"0\" if cables \"None\", \"nan\" or \"1\"\r\n",
    "    df_all_lines[\"cables\"] = df_all_lines[\"cables\"].astype(\"int\")\r\n",
    "if 4 or 5 in df_all_lines[\"cables\"].values: # downgrade 4 and 5 cables to 3... \r\n",
    "    # Reason: 4 cables have 1 lighting protection cables, 5 cables has 2 LP cables - not transferring energy; \r\n",
    "    # see https://hackaday.com/2019/06/11/a-field-guide-to-transmission-lines/\r\n",
    "    df_all_lines.loc[(df_all_lines[\"cables\"] == 4) | (df_all_lines[\"cables\"] == 5), \"cables\"] = 3 # where circuits are \"0\" make \"1\"\r\n",
    "df_all_lines.loc[df_all_lines[\"circuits\"].isna(), \"circuits\"] = df_all_lines.loc[df_all_lines['circuits'].isna(), \"cables\"] / 3 # one circuit contains 3 cables\r\n",
    "df_all_lines[\"circuits\"] = df_all_lines[\"circuits\"].astype(int)\r\n",
    "df_all_lines.loc[(df_all_lines[\"circuits\"] == \"0\") | (df_all_lines[\"circuits\"] == 0), \"circuits\"] = 1 # where circuits are \"0\" make \"1\"\r\n",
    "\r\n",
    "if 'cables' in df_all_lines: # drop column if exist\r\n",
    "    df_all_lines.drop(columns = \"cables\", inplace=True)\r\n",
    "\r\n",
    "# df_all_lines[\"circuits\"].unique()\r\n",
    "# df_all_lines[\"cables\"].unique()\r\n",
    "# display(df_all_lines)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Clean voltage"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "# Drop any row with Voltage = N/A\r\n",
    "df = df_all_lines.dropna(subset=['voltage']) \r\n",
    "\r\n",
    "#Split semicolon separated cells i.e. [66000;220000] and create new identical rows\r\n",
    "lst_col = 'voltage'\r\n",
    "x = df.assign(**{lst_col:df[lst_col].str.split(';')})\r\n",
    "x = pd.DataFrame({\r\n",
    "    col:np.repeat(x[col].values, x[lst_col].str.len())\r\n",
    "    for col in x.columns.difference([lst_col])\r\n",
    "    }).assign(**{lst_col:np.concatenate(x[lst_col].values)})[x.columns.tolist()]\r\n",
    "df_all_lines = x\r\n",
    "\r\n",
    "#display(df_all_lines)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "# Create unique line_id's\r\n",
    "# The steps below create unique line_id's without loosing the original OSM line_id \r\n",
    "\r\n",
    "# Context\r\n",
    "# The previous duplication of rows (to split the voltage) lead to a couple of same line_id (about 30% of dataset)\r\n",
    "\r\n",
    "# Method\r\n",
    "# Unique line_id are created by simply adding -1,-2,-3 to the original line_id\r\n",
    "# Every unique id gets a -1 \r\n",
    "# If a line_id exist i.e. three times it it will the counted by cumcount -1,-2,-3 making the id unique\r\n",
    "\r\n",
    "if df_all_lines[\"line_id\"].count() != df_all_lines[\"line_id\"].nunique(): # operate only if line_id is not already unique (nunique counts unique values)\r\n",
    "    df_all_lines[\"cumcount\"] = df_all_lines.groupby([\"line_id\"]).cumcount() # create cumcount column. Cumcount counts 0,1,2,3 the number of duplicates\r\n",
    "    df_all_lines[\"cumcount\"] = df_all_lines[\"cumcount\"] + 1 # avoid 0 value for better understanding\r\n",
    "    df_all_lines[\"line_id\"] = df_all_lines[\"line_id\"].astype(str) + \"-\" + df_all_lines[\"cumcount\"].values.astype(str) # add cumcount to line_id to make line_id unique\r\n",
    "    df_all_lines.drop(columns = \"cumcount\", inplace=True) # remove cumcount column\r\n",
    "\r\n",
    "#display(df_all_lines)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "# Remove all non-numeric values\r\n",
    "\r\n",
    "df_all_lines.loc[:,\"voltage\"] = df_all_lines['voltage'].apply(lambda x: pd.to_numeric(x, errors='coerce')).astype(float) # if cell can't converted to float -> nan\r\n",
    "df_all_lines = df_all_lines.dropna(subset=['voltage']) # Drop any row with Voltage = N/A\r\n",
    "df_all_lines.loc[:,\"voltage\"]  = df_all_lines['voltage'].astype(int)\r\n",
    "#df_all_lines['voltage'].unique()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Davide\\.conda\\envs\\main_env\\lib\\site-packages\\pandas\\core\\indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "# Keep rows with x > 110 kV as it is considered as transmission level\r\n",
    "df_all_lines = df_all_lines[df_all_lines.voltage > 110000]\r\n",
    "\r\n",
    "# Remove lines that are shorter than 100m\r\n",
    "#df_all_lines = df_all_lines[df_all_lines.length > 100]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "# display(df_all_lines)\r\n",
    "# display(df_all_lines['voltage'].unique())\r\n",
    "# display(df_all_lines['length'].describe())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "## Generate Files (CSV+GeoJSON) \r\n",
    "\r\n",
    "\r\n",
    "### CSV\r\n",
    "outputfile_partial = os.path.join(os.getcwd(), \"data\", \"clean\", \"africa_all\" + \"_lines\" + \"_clean\") # Output file directory\r\n",
    "\r\n",
    "if not os.path.exists(outputfile_partial):\r\n",
    "    os.makedirs(os.path.dirname(outputfile_partial), exist_ok=True) #  create clean directoryif not already exist\r\n",
    "    \r\n",
    "df_all_lines.to_csv(outputfile_partial + \".csv\")  # Generate CSV\r\n",
    "\r\n",
    "\r\n",
    "### GEOJSON\r\n",
    "df_all_lines = gpd.GeoDataFrame(df_all_lines, geometry=\"geometry\",crs=\"EPSG:4326\")\r\n",
    "df_all_lines.to_file(outputfile_partial + \".geojson\", driver=\"GeoJSON\")    \r\n",
    "  \r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:fiona._env:c:\\Users\\Davide\\Git\\pypsa-africa\\data_exploration\\WP5_transmission_assets\\data\\clean\\africa_all_lines_clean.geojson: No such file or directory\n",
      "WARNING:fiona._env:driver GeoJSON does not support creation option ENCODING\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GENERATORS"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "# ----------- Generator -----------\r\n",
    "\r\n",
    "#Load uncleaned data\r\n",
    "df_all_generators = pd.read_csv(os.getcwd()+\"/data/raw/africa_all_raw_generators.csv\")\r\n",
    "\r\n",
    "#Clean data\r\n",
    "df_all_generators = df_all_generators.reset_index(drop=True)\r\n",
    "df_all_generators = df_all_generators[df_all_generators['tags.generator:output:electricity'].astype(str).str.contains('MW')] #removes boolean \r\n",
    "df_all_generators['tags.generator:output:electricity'] = df_all_generators['tags.generator:output:electricity'].str.extract('(\\d+)').astype(float)\r\n",
    "df_all_generators = df_all_generators.rename(columns = {'tags.generator:output:electricity':\"power_output_MW\"})\r\n",
    "\r\n",
    "\r\n",
    "## Generate Files\r\n",
    "\r\n",
    "#CSV\r\n",
    "outputfile_partial = os.path.join(os.getcwd(),'data','africa_all'+'_generators'+'_cleaned.')\r\n",
    "df_all_generators.to_csv(outputfile_partial + 'csv') # Generate CSV\r\n",
    "\r\n",
    "#GeoJSON\r\n",
    "# gdf_generators = convert_pd_to_gdf(df_all_generators)\r\n",
    "# gdf_generators.to_file(outputfile_partial+'geojson', driver=\"GeoJSON\")  # Generate GeoJson\r\n",
    "\r\n",
    "\r\n",
    "#display(df_all_generators)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'to_file'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-cbf868573c51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m#GeoJSON\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m#gdf_generators = convert_pd_to_gdf(df_all_generators)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mdf_all_generators\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputfile_partial\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'geojson'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"GeoJSON\"\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Generate GeoJson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\main_env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5460\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5461\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5462\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5464\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'to_file'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cbcf0b2e79935d7742c74d252ec7ce940852352c30b8b867cd2099d9b0fc11b3"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('main_env': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}