{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "OLD NOTEBOOK: SEE osm_pbf_power_data_extractor.py which does everything."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# check folder\n",
    "\n",
    "import os, sys, time\n",
    "\n",
    "(os.path.abspath(\"\"))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Davide\\\\Git\\\\pypsa-africa\\\\data_exploration\\\\WP5_transmission_assets'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import os, sys, time\n",
    "\n",
    "# IMPORTANT: RUN SCRIPT FROM THIS SCRIPTS DIRECTORY i.e data_exploration/ TODO: make more robust\n",
    "## os.chdir(os.path.dirname(os.path.abspath(__file__)))\n",
    "sys.path.append(\"../../scripts\")\n",
    "from osm_data_config import AFRICA_CC\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString\n",
    "import geoplot\n",
    "import matplotlib.pyplot as plt\n",
    "from osm_data_config import AFRICA_CC\n",
    "from osm_pbf_power_data_extractor import convert_pd_to_gdf_lines, convert_pd_to_gdf\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SUBSTATIONS (Just simple cleaning to test snapping)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check old buses"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Load pypsa-eur data\n",
    "df_all_buses = (\n",
    "    pd.read_csv(\n",
    "        os.getcwd() + \"/entsoegridkit/buses.csv\",\n",
    "        quotechar=\"'\",\n",
    "        true_values=\"t\",\n",
    "        false_values=\"f\",\n",
    "        dtype=dict(bus_id=\"str\"),\n",
    "    )\n",
    "    .set_index(\"bus_id\")\n",
    "    .drop([\"station_id\"], axis=1)\n",
    "    .rename(columns=dict(voltage=\"v_nom\"))\n",
    ")\n",
    "\n",
    "# print(df_all_lines.geometry.unique())\n",
    "# display(df_all_buses)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import data and create final dataframe layout"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# ----------- SUBSTATIONS -----------\n",
    "# Load uncleaned data\n",
    "df_all_substations = gpd.read_file(\n",
    "    os.getcwd() + \"/data/raw/africa_all_raw_substations.geojson\"\n",
    ")\n",
    "\n",
    "# Modification - create final dataframe layout\n",
    "df_all_substations = df_all_substations.rename(\n",
    "    columns={\n",
    "        \"id\": \"bus_id\",\n",
    "        \"tags.voltage\": \"voltage\",\n",
    "        # \"dc\", will be added below\n",
    "        \"tags.power\": \"symbol\",\n",
    "        # \"under_construction\", will be added below\n",
    "        \"tags.substation\": \"tag_substation\",\n",
    "        \"Country\": \"country\",  # new/different to PyPSA-Eur\n",
    "        \"Area\": \"tag_area\",\n",
    "        \"lonlat\": \"geometry\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add NaN as default\n",
    "df_all_substations[\"station_id\"] = np.nan\n",
    "df_all_substations[\"dc\"] = np.nan\n",
    "df_all_substations[\"under_construction\"] = np.nan\n",
    "df_all_substations[\"lon\"] = df_all_substations[\"geometry\"].x\n",
    "df_all_substations[\"lat\"] = df_all_substations[\"geometry\"].y\n",
    "\n",
    "# Rearrange columns\n",
    "clist = [\n",
    "    \"bus_id\",\n",
    "    \"station_id\",\n",
    "    \"voltage\",\n",
    "    \"dc\",\n",
    "    \"symbol\",\n",
    "    \"under_construction\",\n",
    "    \"tag_substation\",\n",
    "    \"tag_area\",\n",
    "    \"lon\",\n",
    "    \"lat\",\n",
    "    \"geometry\",\n",
    "    \"country\",\n",
    "]\n",
    "df_all_substations = df_all_substations[clist]\n",
    "\n",
    "# make float to integer\n",
    "df_all_substations[\"bus_id\"] = df_all_substations[\"bus_id\"].astype(int)\n",
    "\n",
    "# display(df_all_substations)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define under_construction, dc, filter \"transmission\""
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "df_all_substations[\"under_construction\"] = True\n",
    "df_all_substations[\"dc\"] = False\n",
    "df_all_substations = df_all_substations[\n",
    "    df_all_substations[\"tag_substation\"] == \"transmission\"\n",
    "]  # keep only rows with indexed \"transmission\"\n",
    "# display(df_all_substations)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# df_all_substations.tags_area.count()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# df_all_substations[df_all_substations[\"tags_substation\"] == \"transmission\"].tags_area.describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# df_all_substations[df_all_substations[\"tags_substation\"] == \"distribution\"].tags_area.describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# df_all_substations[df_all_substations[\"tags_substation\"] == \"industrial\"].tags_area.describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# df_all_substations[df_all_substations[\"tags_substation\"].isna()].tags_area.describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# df_all_substations[\"tags_substation\"].unique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Clean voltage"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# Drop any row with Voltage = N/A\n",
    "df = df_all_substations.dropna(subset=[\"voltage\"])\n",
    "\n",
    "# Split semicolon separated cells i.e. [66000;220000] and create new identical rows\n",
    "lst_col = \"voltage\"\n",
    "x = df.assign(**{lst_col: df[lst_col].str.split(\";\")})\n",
    "x = pd.DataFrame(\n",
    "    {\n",
    "        col: np.repeat(x[col].values, x[lst_col].str.len())\n",
    "        for col in x.columns.difference([lst_col])\n",
    "    }\n",
    ").assign(**{lst_col: np.concatenate(x[lst_col].values)})[x.columns.tolist()]\n",
    "df_all_substations = x\n",
    "\n",
    "# display(df_all_substations)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# Create unique bus id's\n",
    "# The steps below create unique bus id's without loosing the original OSM bus_id\n",
    "\n",
    "# Context\n",
    "# The previous duplication of rows (to split the voltage) lead to a couple of same bus_id\n",
    "\n",
    "# Method\n",
    "# Unique bus_id are created by simply adding -1,-2,-3 to the original bus_id\n",
    "# Every unique id gets a -1\n",
    "# If a bus_id exist i.e. three times it it will the counted by cumcount -1,-2,-3 making the id unique\n",
    "\n",
    "if (\n",
    "    df_all_substations[\"bus_id\"].count() != df_all_substations[\"bus_id\"].nunique()\n",
    "):  # operate only if line_id is not already unique (nunique counts unique values)\n",
    "    df_all_substations[\"cumcount\"] = df_all_substations.groupby(\n",
    "        [\"bus_id\"]\n",
    "    ).cumcount()  # create cumcount column. Cumcount counts 0,1,2,3 the number of duplicates\n",
    "    df_all_substations[\"cumcount\"] = (\n",
    "        df_all_substations[\"cumcount\"] + 1\n",
    "    )  # avoid 0 value for better understanding\n",
    "    df_all_substations[\"bus_id\"] = (\n",
    "        df_all_substations[\"bus_id\"].astype(str)\n",
    "        + \"-\"\n",
    "        + df_all_substations[\"cumcount\"].values.astype(str)\n",
    "    )  # add cumcount to line_id to make line_id unique\n",
    "    df_all_substations.drop(columns=\"cumcount\", inplace=True)  # remove cumcount column\n",
    "# display(df_all_substations)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# Remove all non-numeric values\n",
    "\n",
    "df_all_substations[\"voltage\"] = (\n",
    "    df_all_substations[\"voltage\"]\n",
    "    .apply(lambda x: pd.to_numeric(x, errors=\"coerce\"))\n",
    "    .astype(float)\n",
    ")  # if cell can't converted to float -> nan\n",
    "df_all_substations = df_all_substations.dropna(\n",
    "    subset=[\"voltage\"]\n",
    ")  # Drop any row with Voltage = N/A\n",
    "df_all_substations.loc[:, \"voltage\"] = df_all_substations[\"voltage\"].astype(int)\n",
    "# df_all_lines['voltage'].unique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "# Keep rows with x > 110 kV as it is considered as transmission level\n",
    "\n",
    "df_all_substations = df_all_substations[df_all_substations.voltage > 110000]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "# display(df_all_substations)\n",
    "# display(df_all_substations['voltage'].unique())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "## Generate Files (CSV+GeoJSON)\n",
    "\n",
    "#### CSV\n",
    "outputfile_partial = os.path.join(\n",
    "    os.getcwd(), \"data\", \"clean\", \"africa_all\" + \"_buses\" + \"_clean\"\n",
    ")  # Output file directory\n",
    "\n",
    "if not os.path.exists(outputfile_partial):\n",
    "    os.makedirs(\n",
    "        os.path.dirname(outputfile_partial), exist_ok=True\n",
    "    )  #  create clean directoryif not already exist\n",
    "df_all_substations.to_csv(outputfile_partial + \".csv\")  # Generate CSV\n",
    "\n",
    "\n",
    "#### GEOJSON\n",
    "\n",
    "df_all_substations = gpd.GeoDataFrame(\n",
    "    df_all_substations, geometry=\"geometry\", crs=\"EPSG:4326\"\n",
    ")\n",
    "df_all_substations.to_file(outputfile_partial + \".geojson\", driver=\"GeoJSON\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:fiona._env:c:\\Users\\Davide\\Git\\pypsa-africa\\data_exploration\\WP5_transmission_assets\\data\\clean\\africa_all_buses_clean.geojson: No such file or directory\n",
      "WARNING:fiona._env:driver GeoJSON does not support creation option ENCODING\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LINES "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check old unique values"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "# Load pypsa-eur data\n",
    "df_all_lines = (\n",
    "    pd.read_csv(\n",
    "        os.getcwd() + \"/entsoegridkit/lines.csv\",\n",
    "        quotechar=\"'\",\n",
    "        true_values=\"t\",\n",
    "        false_values=\"f\",\n",
    "        dtype=dict(\n",
    "            line_id=\"str\",\n",
    "            bus0=\"str\",\n",
    "            bus1=\"str\",\n",
    "            underground=\"bool\",\n",
    "            under_construction=\"bool\",\n",
    "        ),\n",
    "    )\n",
    "    .set_index(\"line_id\")\n",
    "    .rename(columns=dict(voltage=\"v_nom\", circuits=\"num_parallel\"))\n",
    ")\n",
    "\n",
    "# print(df_all_lines.geometry.unique())\n",
    "# display(df_all_lines)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import data and create final dataframe layout"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load cables"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "# Load raw cable data\n",
    "df_cables = gpd.read_file(os.getcwd() + \"/data/raw/africa_all_raw_cables.geojson\")\n",
    "\n",
    "# Modification - create final dataframe layout\n",
    "df_cables = df_cables.rename(\n",
    "    columns={\n",
    "        \"id\": \"line_id\",\n",
    "        \"tags.voltage\": \"voltage\",\n",
    "        \"tags.circuits\": \"circuits\",\n",
    "        \"tags.cables\": \"cables\",\n",
    "        \"tags.frequency\": \"tag_frequency\",\n",
    "        \"tags.power\": \"tag_type\",\n",
    "        \"tags.location\": \"tag_location\",\n",
    "        \"lonlat\": \"geometry\",\n",
    "        \"Country\": \"country\",  # new/different to PyPSA-Eur\n",
    "        \"Length\": \"length\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add NaN as default\n",
    "df_cables[\"bus0\"] = np.nan\n",
    "df_cables[\"bus1\"] = np.nan\n",
    "# df_all_cables[\"length\"] = np.nan # Now in dataset\n",
    "df_cables[\"underground\"] = np.nan\n",
    "df_cables[\"under_construction\"] = np.nan\n",
    "\n",
    "# Rearrange columns\n",
    "clist = [\n",
    "    \"line_id\",\n",
    "    \"bus0\",\n",
    "    \"bus1\",\n",
    "    \"voltage\",\n",
    "    \"circuits\",\n",
    "    \"length\",\n",
    "    \"underground\",\n",
    "    \"under_construction\",\n",
    "    \"tag_type\",\n",
    "    \"tag_frequency\",\n",
    "    \"tag_location\",\n",
    "    \"geometry\",\n",
    "    \"country\",\n",
    "]\n",
    "df_cables = df_cables[clist]\n",
    "\n",
    "# make float to integer\n",
    "df_cables[\"line_id\"] = df_cables[\"line_id\"].astype(int)\n",
    "\n",
    "\n",
    "# display(df_cables)\n",
    "# df_all_cables[df_all_cables['tag_location']== \"overground\"]\n",
    "# df_all_cables[\"tags.location\"].unique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load lines"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "# Load raw line data\n",
    "df_lines = gpd.read_file(os.getcwd() + \"/data/raw/africa_all_raw_lines.geojson\")\n",
    "\n",
    "# Modification - create final dataframe layout\n",
    "df_lines = df_lines.rename(\n",
    "    columns={\n",
    "        \"id\": \"line_id\",\n",
    "        \"tags.voltage\": \"voltage\",\n",
    "        \"tags.circuits\": \"circuits\",\n",
    "        \"tags.cables\": \"cables\",\n",
    "        \"tags.frequency\": \"tag_frequency\",\n",
    "        \"tags.power\": \"tag_type\",\n",
    "        \"lonlat\": \"geometry\",\n",
    "        \"Country\": \"country\",  # new/different to PyPSA-Eur\n",
    "        \"Length\": \"length\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add NaN as default\n",
    "df_lines[\"bus0\"] = np.nan\n",
    "df_lines[\"bus1\"] = np.nan\n",
    "# df_all_lines[\"length\"] = np.nan # commented because, we have now length data\n",
    "df_lines[\"underground\"] = np.nan\n",
    "df_lines[\"under_construction\"] = np.nan\n",
    "\n",
    "# Rearrange columns\n",
    "clist = [\n",
    "    \"line_id\",\n",
    "    \"bus0\",\n",
    "    \"bus1\",\n",
    "    \"voltage\",\n",
    "    \"circuits\",\n",
    "    \"length\",\n",
    "    \"underground\",\n",
    "    \"under_construction\",\n",
    "    \"tag_type\",\n",
    "    \"tag_frequency\",\n",
    "    \"cables\",\n",
    "    \"geometry\",\n",
    "    \"country\",\n",
    "]\n",
    "df_lines = df_lines[clist]\n",
    "\n",
    "# display(df_all_lines)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combine cable and line to one  \"df_all_lines\" dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "df_all_lines = pd.concat([df_lines, df_cables])\n",
    "# df_all_lines"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define underground, under_construction information, frequency, circuits"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "# under construction\n",
    "df_all_lines[\n",
    "    \"under_construction\"\n",
    "] = False  # default. Not more information atm available\n",
    "\n",
    "# underground\n",
    "df_all_lines[\"underground\"] = (\n",
    "    df_all_lines[\"tag_type\"] == \"cable\"\n",
    ")  # Simplified. If tag_type cable then underground is True.\n",
    "# More information extractable for \"underground\" by looking at \"tag_location\".\n",
    "if \"tag_location\" in df_all_lines:  # drop column if exist\n",
    "    df_all_lines.drop(columns=\"tag_location\", inplace=True)\n",
    "# frequency\n",
    "df_all_lines[\"tag_frequency\"] = 50\n",
    "# df_all_lines[\"tag_frequency\"].unique()\n",
    "\n",
    "# circuits\n",
    "if df_all_lines[\"cables\"].dtype != int:  # if not int make int\n",
    "    df_all_lines.loc[\n",
    "        (df_all_lines[\"cables\"] < \"3\") | df_all_lines[\"cables\"].isna(), \"cables\"\n",
    "    ] = \"0\"  # HERE. \"0\" if cables \"None\", \"nan\" or \"1\"\n",
    "    df_all_lines[\"cables\"] = df_all_lines[\"cables\"].astype(\"int\")\n",
    "if 4 or 5 in df_all_lines[\"cables\"].values:  # downgrade 4 and 5 cables to 3...\n",
    "    # Reason: 4 cables have 1 lighting protection cables, 5 cables has 2 LP cables - not transferring energy;\n",
    "    # see https://hackaday.com/2019/06/11/a-field-guide-to-transmission-lines/\n",
    "    df_all_lines.loc[\n",
    "        (df_all_lines[\"cables\"] == 4) | (df_all_lines[\"cables\"] == 5), \"cables\"\n",
    "    ] = 3  # where circuits are \"0\" make \"1\"\n",
    "df_all_lines.loc[df_all_lines[\"circuits\"].isna(), \"circuits\"] = (\n",
    "    df_all_lines.loc[df_all_lines[\"circuits\"].isna(), \"cables\"] / 3\n",
    ")  # one circuit contains 3 cables\n",
    "df_all_lines[\"circuits\"] = df_all_lines[\"circuits\"].astype(int)\n",
    "df_all_lines.loc[\n",
    "    (df_all_lines[\"circuits\"] == \"0\") | (df_all_lines[\"circuits\"] == 0), \"circuits\"\n",
    "] = 1  # where circuits are \"0\" make \"1\"\n",
    "\n",
    "if \"cables\" in df_all_lines:  # drop column if exist\n",
    "    df_all_lines.drop(columns=\"cables\", inplace=True)\n",
    "# df_all_lines[\"circuits\"].unique()\n",
    "# df_all_lines[\"cables\"].unique()\n",
    "# display(df_all_lines)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Clean voltage"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "# Drop any row with Voltage = N/A\n",
    "df = df_all_lines.dropna(subset=[\"voltage\"])\n",
    "\n",
    "# Split semicolon separated cells i.e. [66000;220000] and create new identical rows\n",
    "lst_col = \"voltage\"\n",
    "x = df.assign(**{lst_col: df[lst_col].str.split(\";\")})\n",
    "x = pd.DataFrame(\n",
    "    {\n",
    "        col: np.repeat(x[col].values, x[lst_col].str.len())\n",
    "        for col in x.columns.difference([lst_col])\n",
    "    }\n",
    ").assign(**{lst_col: np.concatenate(x[lst_col].values)})[x.columns.tolist()]\n",
    "df_all_lines = x\n",
    "\n",
    "# display(df_all_lines)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "# Create unique line_id's\n",
    "# The steps below create unique line_id's without loosing the original OSM line_id\n",
    "\n",
    "# Context\n",
    "# The previous duplication of rows (to split the voltage) lead to a couple of same line_id (about 30% of dataset)\n",
    "\n",
    "# Method\n",
    "# Unique line_id are created by simply adding -1,-2,-3 to the original line_id\n",
    "# Every unique id gets a -1\n",
    "# If a line_id exist i.e. three times it it will the counted by cumcount -1,-2,-3 making the id unique\n",
    "\n",
    "if (\n",
    "    df_all_lines[\"line_id\"].count() != df_all_lines[\"line_id\"].nunique()\n",
    "):  # operate only if line_id is not already unique (nunique counts unique values)\n",
    "    df_all_lines[\"cumcount\"] = df_all_lines.groupby(\n",
    "        [\"line_id\"]\n",
    "    ).cumcount()  # create cumcount column. Cumcount counts 0,1,2,3 the number of duplicates\n",
    "    df_all_lines[\"cumcount\"] = (\n",
    "        df_all_lines[\"cumcount\"] + 1\n",
    "    )  # avoid 0 value for better understanding\n",
    "    df_all_lines[\"line_id\"] = (\n",
    "        df_all_lines[\"line_id\"].astype(str)\n",
    "        + \"-\"\n",
    "        + df_all_lines[\"cumcount\"].values.astype(str)\n",
    "    )  # add cumcount to line_id to make line_id unique\n",
    "    df_all_lines.drop(columns=\"cumcount\", inplace=True)  # remove cumcount column\n",
    "# display(df_all_lines)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "# Remove all non-numeric values\n",
    "\n",
    "df_all_lines.loc[:, \"voltage\"] = (\n",
    "    df_all_lines[\"voltage\"]\n",
    "    .apply(lambda x: pd.to_numeric(x, errors=\"coerce\"))\n",
    "    .astype(float)\n",
    ")  # if cell can't converted to float -> nan\n",
    "df_all_lines = df_all_lines.dropna(\n",
    "    subset=[\"voltage\"]\n",
    ")  # Drop any row with Voltage = N/A\n",
    "df_all_lines.loc[:, \"voltage\"] = df_all_lines[\"voltage\"].astype(int)\n",
    "# df_all_lines['voltage'].unique()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Davide\\.conda\\envs\\main_env\\lib\\site-packages\\pandas\\core\\indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "# Keep rows with x > 110 kV as it is considered as transmission level\n",
    "df_all_lines = df_all_lines[df_all_lines.voltage > 110000]\n",
    "\n",
    "# Remove lines that are shorter than 100m\n",
    "# df_all_lines = df_all_lines[df_all_lines.length > 100]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "# display(df_all_lines)\n",
    "# display(df_all_lines['voltage'].unique())\n",
    "# display(df_all_lines['length'].describe())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "## Generate Files (CSV+GeoJSON)\n",
    "\n",
    "\n",
    "### CSV\n",
    "outputfile_partial = os.path.join(\n",
    "    os.getcwd(), \"data\", \"clean\", \"africa_all\" + \"_lines\" + \"_clean\"\n",
    ")  # Output file directory\n",
    "\n",
    "if not os.path.exists(outputfile_partial):\n",
    "    os.makedirs(\n",
    "        os.path.dirname(outputfile_partial), exist_ok=True\n",
    "    )  #  create clean directoryif not already exist\n",
    "df_all_lines.to_csv(outputfile_partial + \".csv\")  # Generate CSV\n",
    "\n",
    "\n",
    "### GEOJSON\n",
    "df_all_lines = gpd.GeoDataFrame(df_all_lines, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "df_all_lines.to_file(outputfile_partial + \".geojson\", driver=\"GeoJSON\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:fiona._env:c:\\Users\\Davide\\Git\\pypsa-africa\\data_exploration\\WP5_transmission_assets\\data\\clean\\africa_all_lines_clean.geojson: No such file or directory\n",
      "WARNING:fiona._env:driver GeoJSON does not support creation option ENCODING\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GENERATORS"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "# ----------- Generator -----------\n",
    "\n",
    "# Load uncleaned data\n",
    "df_all_generators = pd.read_csv(os.getcwd() + \"/data/raw/africa_all_raw_generators.csv\")\n",
    "\n",
    "# Clean data\n",
    "df_all_generators = df_all_generators.reset_index(drop=True)\n",
    "df_all_generators = df_all_generators[\n",
    "    df_all_generators[\"tags.generator:output:electricity\"]\n",
    "    .astype(str)\n",
    "    .str.contains(\"MW\")\n",
    "]  # removes boolean\n",
    "df_all_generators[\"tags.generator:output:electricity\"] = (\n",
    "    df_all_generators[\"tags.generator:output:electricity\"]\n",
    "    .str.extract(\"(\\d+)\")\n",
    "    .astype(float)\n",
    ")\n",
    "df_all_generators = df_all_generators.rename(\n",
    "    columns={\"tags.generator:output:electricity\": \"power_output_MW\"}\n",
    ")\n",
    "\n",
    "\n",
    "## Generate Files\n",
    "\n",
    "# CSV\n",
    "outputfile_partial = os.path.join(\n",
    "    os.getcwd(), \"data\", \"africa_all\" + \"_generators\" + \"_cleaned.\"\n",
    ")\n",
    "df_all_generators.to_csv(outputfile_partial + \"csv\")  # Generate CSV\n",
    "\n",
    "# GeoJSON\n",
    "# gdf_generators = convert_pd_to_gdf(df_all_generators)\n",
    "# gdf_generators.to_file(outputfile_partial+'geojson', driver=\"GeoJSON\")  # Generate GeoJson\n",
    "\n",
    "\n",
    "# display(df_all_generators)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'to_file'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-cbf868573c51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m#GeoJSON\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m#gdf_generators = convert_pd_to_gdf(df_all_generators)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mdf_all_generators\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputfile_partial\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'geojson'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"GeoJSON\"\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Generate GeoJson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\main_env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5460\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5461\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5462\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5464\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'to_file'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cbcf0b2e79935d7742c74d252ec7ce940852352c30b8b867cd2099d9b0fc11b3"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('main_env': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
